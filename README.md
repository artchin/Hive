# Apache Hive

Комплекс задач по аналитике пользовательских логов новостных сайтов.

## Задачи

### 1. Data Modeling
Создание схемы данных из 4 внешних (EXTERNAL) таблиц.

**Таблицы:**
- `Logs` — логи запросов (партиционирована по датам)
- `Users` — данные пользователей
- `IPRegions` — IP-адреса и регионы
- `Subnets` — подсети

**Особенности:**
- Десериализация сырых данных через `RegexSerDe`
- Партиционирование по датам (116 партиций)

### 2. Aggregation
Подсчёт количества посещений по дням с сортировкой по убыванию.

### 3. JOIN + Conditional Aggregation
Аналитика посещений по полу (male/female) в разрезе регионов.

**Реализация:**
- JOIN таблиц `Logs`, `Users`, `IPRegions`
- Условная агрегация через конструкцию `IF`

### 4. Hive Streaming
Трансформация данных через внешний скрипт — массовая замена доменов (`.ru` → `.com`).

**Реализация:**
- Потоковая обработка через `sed/awk`
- Вывод всех 6 полей после трансформации

### 5. Sampling & Analysis
Исследование точности семплирования (`TABLESAMPLE`) на больших данных.

**Реализация:**
- Сравнение результатов при разных процентах выборки
- Построение графика зависимости точности от размера семпла

## Оптимизации

| Параметр | Назначение |
|----------|------------|
| `hive.exec.parallel` | Параллельное выполнение задач |
| `mapreduce.job.reduces` | Настройка числа reducer'ов |
| `hive.exec.max.dynamic.partitions` | Управление динамическими партициями |

## Stack

| Технология | Назначение |
|------------|------------|
| Apache Hive | SQL-движок над Hadoop |
| HiveQL | Язык запросов |
| RegexSerDe | Десериализация через регулярные выражения |
| Hive Streaming | Потоковая обработка (Bash, sed/awk) |
| TABLESAMPLE | Семплирование данных |

## Результаты

- Снижение времени выполнения запросов за счёт партиционирования
- Оптимизация через параллельное выполнение
- Код проверен тестами преподавателей ШАД
